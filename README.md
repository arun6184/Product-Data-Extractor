# World of Books Scraper - Product Data Explorer

A full-stack web scraping platform for exploring and discovering books from [World of Books](https://www.worldofbooks.com/). Built with **Next.js**, **NestJS**, **Crawlee**, and **Playwright** for on-demand scraping, intelligent caching, and a modern browsing experience.

---

## ğŸš€ Features

- **On-Demand Web Scraping** â€“ Scrape navigation, categories, products, and product details using Crawlee + Playwright
- **Intelligent Caching** â€“ Database-based TTL caching (24h navigation, 12h categories, 6h products)
- **Full REST API** â€“ NestJS backend with Swagger documentation
- **Modern Frontend** â€“ Next.js 14 App Router with SWR for data fetching
- **Browsing History** â€“ Track user browsing with session management
- **Responsive Design** â€“ Mobile-first Tailwind CSS styling
- **Production-Ready** â€“ Error handling, retry logic, rate limiting, and logging

---

## ğŸ“ Project Structure

```
Data Explorer/
â”œâ”€â”€ backend/               # NestJS API + Scraper
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”‚   â”œâ”€â”€ navigation/
â”‚   â”‚   â”‚   â”œâ”€â”€ category/
â”‚   â”‚   â”‚   â”œâ”€â”€ product/
â”‚   â”‚   â”‚   â”œâ”€â”€ product-detail/
â”‚   â”‚   â”‚   â”œâ”€â”€ review/
â”‚   â”‚   â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”‚   â””â”€â”€ history/
â”‚   â”‚   â””â”€â”€ config/
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ frontend/             # Next.js Application
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ app/          # App Router pages
    â”‚   â”œâ”€â”€ components/   # React components
    â”‚   â”œâ”€â”€ hooks/        # SWR data fetching hooks
    â”‚   â”œâ”€â”€ lib/          # API client & utilities
    â”‚   â””â”€â”€ types/        # TypeScript types
    â””â”€â”€ package.json
```

---

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework:** NestJS 10
- **Database:** PostgreSQL (TypeORM)
- **Scraping:** Crawlee 3.7 + Playwright 1.40
- **Validation:** class-validator, class-transformer
- **Documentation:** Swagger/OpenAPI

### Frontend
- **Framework:** Next.js 14 (App Router)
- **Language:** TypeScript
- **Styling:** Tailwind CSS
- **Data Fetching:** SWR
- **HTTP Client:** Axios

---

## âš™ï¸ Installation & Setup

### Prerequisites
- Node.js 18+ and npm
- PostgreSQL 15+
- Git

### 1. Clone Repository
```bash
cd "D:/Projects/Data Explorer"
```

### 2. Backend Setup

```bash
cd backend

# Install dependencies
npm install

# Copy environment file
copy .env.example .env

# Edit .env with your PostgreSQL credentials
# DATABASE_HOST=localhost
# DATABASE_PORT=5432
# DATABASE_USER=postgres
# DATABASE_PASSWORD=your_password
# DATABASE_NAME=worldofbooks_scraper

# Start development server
npm run start:dev
```

Backend will run on **http://localhost:3001**
Swagger docs: **http://localhost:3001/api/docs**

### 3. Frontend Setup

```bash
cd ../frontend

# Install dependencies
npm install

# Copy environment file
copy .env.local.example .env.local

# Edit .env.local (default values should work)
# NEXT_PUBLIC_API_URL=http://localhost:3001/api

# Start development server
npm run dev
```

Frontend will run on **http://localhost:3000**

---

## ğŸ“– Usage

### 1. Scrape Navigation
```bash
curl -X POST http://localhost:3001/api/navigation/scrape
```

### 2. Scrape Categories
```bash
curl -X POST "http://localhost:3001/api/categories/scrape?navigationUrl=https://www.worldofbooks.com/en-gb/books&navigationId=<nav-id>"
```

### 3. Scrape Products
```bash
curl -X POST http://localhost:3001/api/products/scrape \
  -H "Content-Type: application/json" \
  -d '{
    "categoryUrl": "https://www.worldofbooks.com/en-gb/books/fiction",
    "categoryId": "<category-id>",
    "maxPages": 5
  }'
```

### 4. Browse Frontend
Visit **http://localhost:3000** and explore:
- Home page with hero and features
- Categories listing
- Products with search and pagination
- Product detail pages with reviews
- Browsing history

---

## ğŸŒ API Endpoints

### Navigation
- `GET /api/navigation` â€“ Get all navigation items
- `POST /api/navigation/scrape` â€“ Trigger scraping

### Categories
- `GET /api/categories` â€“ Get categories (filter by `navigationId`, `parentId`)
- `GET /api/categories/:id` â€“ Get single category
- `GET /api/categories/:id/subcategories` â€“ Get subcategories
- `POST /api/categories/scrape` â€“ Trigger scraping

### Products
- `GET /api/products` â€“ List products (pagination, search, filters)
- `GET /api/products/:id` â€“ Get product by ID
- `GET /api/products/:id/details` â€“ Get product details
- `GET /api/products/:id/reviews` â€“ Get product reviews
- `POST /api/products/scrape` â€“ Scrape products
- `POST /api/products/:id/scrape-details` â€“ Scrape product details

### History
- `GET /api/history?sessionId=<id>` â€“ Get browsing history
- `POST /api/history` â€“ Add history entry
- `DELETE /api/history/:id` â€“ Remove entry
- `DELETE /api/history/session/:sessionId` â€“ Clear session

---

## ğŸ—„ï¸ Database Schema

```sql
-- Core entities
navigation (id, name, url, position, isActive, lastScrapedAt)
category (id, name, slug, url, description, imageUrl, parentId, navigationId, lastScrapedAt)
product (id, sku, title, url, imageUrl, price, originalPrice, condition, inStock, author, isbn, rating, reviewCount, categoryId, lastScrapedAt)
product_detail (id, productId, description, publisher, publicationDate, language, pages, format, images, specifications, relatedProducts, lastScrapedAt)
review (id, productId, reviewerName, rating, title, content, reviewDate, isVerifiedPurchase, helpfulCount)
scrape_job (id, type, status, url, params, itemsProcessed, itemsTotal, errorMessage, result, startedAt, completedAt)
view_history (id, sessionId, entityType, entityId, title, url, imageUrl, metadata, createdAt)
```

---

## ğŸš¢ Deployment

### Frontend (Vercel)
```bash
cd frontend
vercel --prod
```

Set environment variable:
- `NEXT_PUBLIC_API_URL=<your-backend-url>/api`

### Backend (Render / Fly.io)
```bash
cd backend
# Deploy to Render or Fly.io
# Set environment variables in platform dashboard
```

Environment variables needed:
- `DATABASE_URL` or individual DB config
- `NODE_ENV=production`
- `CORS_ORIGIN=<frontend-url>`

### Database (Neon / Supabase)
- Create PostgreSQL instance
- Copy connection string
- Update backend environment

---

## ğŸ“ License

MIT

---

## ğŸ‘¤ Author

@arun6184

---

## ğŸŒŸ Architecture Highlights

- **Modular Design** â€“ Separate modules for each entity
- **Retry Logic** â€“ Exponential backoff on scraper failures
- **Rate Limiting** â€“ 2-3 second delays between requests
- **Cache Strategy** â€“ TTL-based database caching
- **Type Safety** â€“ Full TypeScript coverage
- **Responsive UI** â€“ Mobile-first design
- **Session Tracking** â€“ LocalStorage-based history
